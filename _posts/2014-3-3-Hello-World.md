---
layout: post
title: Lion Share!
---

Lion Share
The lack of existing validation system that isolates the request validation from service rendering, forces the queue to be overcrowded with invalidated requests and insecure hits. The least effort to the validation of the existing system leaves the service provider insecure and busy. 


Crowding a highly rated service providers' queue will deprecate the quality of service provider which is meant to provide and vice versa. The survey shows that there is a need for such model that deals the queue length as a random variable that most likely chooses a queue with lower length and with best effort service.The interceptor is introduced to have an efficient flow of service without any web security threat such as passing requests from clients without proper validation. This approach further integrates a sanitizer module which discards the invalid requests sent by any client and promotes efficiency. Further it establishes a time-sensitive service with minimum waiting time and consistent performance in quality. 

The interceptor allows a valid request to hit the service and the response will be given accordingly. In case of any delay the interceptor duly intimates the client and the client will be kept posted in time. The motivation behind the interceptor module is to isolate the request validation from the service provider.keeps any chores except the core business in hand. The round trip time will be stamped along with the service reply.his method reduces the traffic at the service provider queue into the remarkable level. The service provider will find considerable elbow room and the response time will be improved into new high as provider need not to examine the validity of service request. Interceptor and probabilistic approach attempts to design an efficient flow of service without any web security threats. 

This approach establishes a time sensitive service with minimum waiting time and consistent performance. In the architecture depicted in Figure 11, there is the probabilistic model which distributes the request randomly and asynchronously but always tries to insert the request into the queue which has minimal waiting time. Thus it produces normalized probabilistic model.  Once the request taken out from the queue, it is delivered to the interceptor that has validation and sanitization module. Registration of service requestor, Signature & IP Verification, Attempts Check and Sanitizer are the processes in interceptor module. 


The cryptographically protected pseudo random number producer generates the token and the whitelist is populated with either the token or seed.Using a signature_Token is better than the conventional authentication schemes, which aids in dealing of Denial of Service attack. Although the occurrences of the request are increased by the attacker, it is constrained that the token/seed would be useable only for the specified amount of time or until it is alive. As the invalid request and corresponding error message is sent back to the client. Here for the signature verification module MD5 algorithm is used that takes token and password as parameters to generate the signature token as signature validation, which takes user name and password and gives yes to client considered as a token from the white list. White list gives the permitted tokens and black list lists non permitted tokens. If the token is not in the white list the request will be denied with the error message otherwise sent to IP verification module. It checks that the IP address of client is valid by using either whitelist or blacklist. 


The blacklist holds a set of client’s IP address that made threat to the service provider.In IP verification, first step is signature validation which is followed by IP verification module. Considering IP whitelist and Blacklist, any IP which is in the white list will be allowed otherwise it will be declined. If IP address is in IP white list and not in the IP blacklist then success otherwise invalid request. Attempt check module finds the running time of any attempt and if the running time is greater than the constant time (allowed time) then the request will be invalid.The schema caching process is maintained by the sanitizer which is the process of maintaining local copies of the schema. This is supposed to be updated regularly as changes are made to the schema. The local schema repository can be easily manipulated just like folders, by using the namespaces names to provide guidance on naming the folders..This is basically an attempt to protect the schema from any possible attacks. The sanitizer consists of a whitelist with a set of valid parameters that needs to verify the client request with the XML specification, which limits XML injection and oversize payload attacks. 

The whitelist should contain Element Names / Parameter Names - All the elements that are used in the schema should be listed in the whitelist. On considering the schema, the unrestrained incidence must be limited till further end, since that is the main reason for coercive parsing attack. Thus, these incidents would like to be detained with respect to the kind of application in use. As namespace injection attack are likely to occur an each namespaces and related tags are monitored and these details are enlisted inside the whitelist in order to provide authentication.The predefined input policies of the ports and services should be enforced so that improved security will be enforced.  The XSDPath is extracted from XML form of service request and checked up  if empty, in case of the value is null the request will be forbidden and the error message will be conveyed  to the client to avoid the parameter tampering attack.  Further the threshold of the magnitude of the service request message is enforced and any message that exceeds the stipulated size would be rejected. 


Thus the coercive parsing attack is handled. Therefore the sanitizer module authenticates the data in contradiction of the XML stipulations and upholds the data correctness, completeness and structure.It helps to manage best possibility and providing the balance and helps to retain the quality parameters for the segments. The probabilistic approach tends to provide the probability distribution for service selection. It is useful in time-sensitive services. Probabilistic approach ensures best management of queues. Providing balance among providers helps retain quality parameter for further segments. User send the request which will be distributed through probabilistic model with optimal queue length and it helps you to choose the less crowded queue and that is given to the interceptors which checks the registration and verifies IP for sanitization.  Crowding a highly rated service providers' queue will deprecate the quality that the service provider promise to provide and the vice versa. The survey shows that this is such a model that takes the queue length as a random variable and choosing a queue with lower length to be occurred most likely. The probabilistic model should be assuming a normal distribution with the mean value of minimum queue length. It enques any request into the queue likely to have lower queue length.Asynchronous queuing provide a synchronous service illusion  that hides the validation logic for the service call into a shared call and then phase the inbound request on a service message queue for processing at a later period. If the service request validates then it can be placed on the queue for processing and a 'success' response issued to the requester immediately. A failure will cause an error response to the service consumer. The message is then abandoned and not placed in the queue. The arrival of the series of service requests that come to web service environment follows the distribution of Poisson with  λ as mean arrival rate.  Every request of user is meant to select one service provider among the m parallel candidates [M i ]im=1  for finishing the request. The user spares Tp time to finish planning routines such as binding provider and transmitting data. The parameters Tp, l, and μ are presumed to be not a variable during the queuing duration of the  service requests differs based on these request and response. Any request j needs the necessary details at time t of  service level parameter and queue length from the broker before the selection of service provider. The non-probabilistic strategy J is to select the service provider by which the request might anticipate to be completed in the minimum duration: Now during the evaluation of expected time, every request will choose the one with the lowest expected time. Considering the time period when M1 acquires the position of the best provider, say Dt just before the interval t, the requestors of the service are incoming while this recess must have completed the similar opportunity to tie M1. So, when J commences to queue on time t+Tp, it discovers the finding of queue is lengthier than its anticipation and it may not deliver the similar quality of service. Thus it causes periodic fluctuation in the queue length and causes a drastic increase in the peak queue length.


The A mixed strategy is based on theory of games. It means that a service requester does not straight away select the service provider which has least expected time, but picked up a service provider Mi  which has the probability ρI >=0, i=1,2,...,m, to  satisfy Ηere ρI  is sampled from pi.  They are diligently associated to one another, and the various p distributions are calculated using different ρI samplings. However, once considering J users and additional requests are assumed as dissimilar players in a game, p and ρi will have dissimilar computational features because, for other users J might not agree the similar stratagem.Our top priority is to optimize the QOS parameter of service queues so as to provide and retain of quality of the service providers. A more balanced distribution using probabilistic approach can drastically utilize the remaining service providers of mediocre quality parameter as well as improve the efficiency of best by reducing its queue peak length. We are considering three service providers which provide different quality parameter with the top one providing the best quality parameter and the bottom one providing least. We provide a distribution of service requests using probabilistic approach to each of the service provider. It is well noted that any number of request may arrive at a particular interval of time. The utility of asynchronous queues can further provide improve the user response operation. Providing a balance of distribution of requests among the providers helps them to retain their quality parameter for further segments.


 Moreover it also make use of quality of other queues than simply targeting the best provider. A probabilistic approach can ensure the best management of queues and eventually reduces peak queue length and unnecessary congestion. In summary, the interceptor module approach and probabilistic queue approach altogether improve the web service system performance at greater level. The  separation of service request validation from the business entity ameliorates the performance of the system directly. The likelihood approach places the request into better queues that helps the request likely to not wait in a longer queue. Overall, the reliability and availability benchmarks are improved by the probabilistic approach and interceptor module.  



